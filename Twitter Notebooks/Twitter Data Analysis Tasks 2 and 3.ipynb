{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDwep1K8Erxl"
   },
   "source": [
    "**Project:** Data Minining Project for  X company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7-ii3uyI8KY"
   },
   "source": [
    "The CRISP-DM Framework\n",
    "\n",
    "\n",
    "The CRISP-DM methodology provides a structured approach to planning a data mining project. It is a robust and well-proven methodology.\n",
    "* Business understanding (BU): Determine Business Objectives, Assess Situation, Determine Data Mining Goals, Produce Project Plan\n",
    "\n",
    "* Data understanding (DU): Collect Initial Data, Describe Data, Explore Data, Verify Data Quality\n",
    "\n",
    "* Data preparation (DP): Select Data, Clean Data, Construct Data, Integrate Data\n",
    "\n",
    "* Modeling (M): Select modeling technique, Generate Test Design, Build Model, Assess Model\n",
    "*  Evaluation (E): Evaluate Results, Review Process, Determine Next Steps\n",
    "*  Deployment (D): Plan Deployment, Plan Monitoring and Maintenance, Produce Final Report, Review Project\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "[What is the CRISP-DM methodology?](https://www.sv-europe.com/crisp-dm-methodology/)\n",
    "\n",
    "[Introduction to CRISP DM Framework for Data Science and Machine Learning](https://www.linkedin.com/pulse/chapter-1-introduction-crisp-dm-framework-data-science-anshul-roy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lo7Ml7tMQOf"
   },
   "source": [
    "**Data Set**\n",
    "### The data is for company X which is trying to control attrition. \n",
    "### There are two sets of data: \"Existing employees\" and \"Employees who have left\". The following attributes are available for every employee.\n",
    "\n",
    "\n",
    "*   Satisfaction Level\n",
    "\n",
    "*   Last evaluation\n",
    "\n",
    "*   Number of projects\n",
    "\n",
    "*   Average monthly hours\n",
    "\n",
    "*   Time spent at the company\n",
    "*   Whether they have had a work accident\n",
    "\n",
    "\n",
    "*  Whether they have had a promotion in the last 5 years\n",
    "\n",
    "\n",
    "*   Departments (column sales)\n",
    "\n",
    "\n",
    "*   Salary\n",
    "\n",
    "\n",
    "*  Whether the employee has left\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjSj2A2sSph_"
   },
   "source": [
    "**Your Role**\n",
    " \n",
    "\n",
    "*   As data science team member X company asked you to answer this two questions.\n",
    "*  What type of employees is leaving? \n",
    "\n",
    "*   Determine which employees are prone to leave next.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajdEVA7LiBUp"
   },
   "source": [
    "Business Understanding\n",
    "\n",
    "---\n",
    "\n",
    "This step mostly focuses on understanding the Business in all the different aspects. It follows the below different steps.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Identify the goal and frame the business problem.\n",
    "* Prepare Analytical Goal i.e. what type of performance metric and loss function to use\n",
    "* Gather information on resource, constraints, assumptions, risks etc\n",
    "* Gather information on resource, constraints, assumptions, risks etc\n",
    "*   Prepare Work Flow Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4MwiCYzj2_u"
   },
   "source": [
    "### Write the main objectives of this project in your words?\n",
    "minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STyLda45j1Mf"
   },
   "outputs": [],
   "source": [
    "main_objectives ='''\n",
    "The main objective of this project is to help Company X solve employee attrition, which is one of its business problems.\n",
    "Specifically, we are trying to determine which employees are prone to leaving and which one is most likely to leave next. This will be determined by using employee attributes and past employee information. \n",
    "By being able to predict employee attrition, employers can be able to save costs on hiring and training new employees and instead focus their resources on discovering ways to retain their already existing employees.\n",
    "By understanding the business we should be able to collect and prepare the data, build and evaluate a model and successfully deploy it.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuOlxLxKMOLI"
   },
   "outputs": [],
   "source": [
    "assert len(main_objectives) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(main_objectives) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyXeNxlCkbaw"
   },
   "source": [
    "### Outline the different data analysis steps you will follow to carry out the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rC-tl8sUksQq"
   },
   "outputs": [],
   "source": [
    "dm_outline = '''\n",
    "Start by understanding the business, its objectives, the purpose of the project and the kind of \n",
    "decision the company is trying to make.After understanding the business we then proceed to understanding the data.\n",
    "This will involve collecting data, which for this project will involve collecting employee features of past and \n",
    "current employees. We will also explore and verify that the data quality is sufficient enough to achieve the purpose\n",
    "of the project, which in this case involves predicting employee attrition. Then we will clean the date and integrate it \n",
    "so as to prepare it for modelling, where we will select, build and assess modelling techniques.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-K1mWuDoksTk"
   },
   "outputs": [],
   "source": [
    "assert len(dm_outline) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(dm_outline) > 70 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmUDFG1wkzUy"
   },
   "source": [
    "### What metrics will you use to measure the performance of your data analysis model? \n",
    "Write the equations of the metrics here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCNulojKk_BP"
   },
   "source": [
    "e.g. Precision = $\\frac{TP}{(TP + FP)}$\n",
    "\n",
    "Recall = $\\frac{TP}{(TP+FN)}$\n",
    "\n",
    "F1_Score = $\\frac{(2*Precision*Recall)}{(Precision+Recall)}$\n",
    "\n",
    "Accuracy = $\\frac{(TP +TN)}{(TP+FP+TN+FN)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLS2YHoRk_EK"
   },
   "source": [
    "Why do you choose these metrics? minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSynT14KlPSJ"
   },
   "outputs": [],
   "source": [
    "why_metrics = '''\n",
    "The employee attrition problem could be solved by building a classification machine learning algorithm.\n",
    "For classification models, accuracy, precision, recall and the F1-score are good methods to evaluate their performance.\n",
    "Precision tells us of all positive predictions  how many did we predict correctly. Recall tells us of all actual positive\n",
    "observations, what fraction did we get correctly. So a classifier model that has a high precision and high recall is a \n",
    "good classifier since it's picky but gets almost all actual observations correct. However,this depends on the nature of\n",
    "the project. We should also pick a classifier that maximizes the F1 Score  The employee attrition problem could be solved\n",
    "by building a classification machine learning algorithm. For classification models, accuracy, precision, recall and the\n",
    "F1-score are good methods to evaluate their performance. Precision tells us of all positive predictions  how many did we\n",
    "predict correctly. Recall tells us of all actual positive observations, what fraction did we get correctly. So a classifier\n",
    "model that has a high precision and high recall is a good classifier since it's picky but gets almost all actual\n",
    "observations correct. However,  this depends on the nature of the project. We should also pick a classifier that \n",
    "maximizes the F1 Score  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr-Mk0E8lPVJ"
   },
   "outputs": [],
   "source": [
    "assert len(why_metrics) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(why_metrics) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAo19Ip6lUtm"
   },
   "source": [
    "### How would you know if your data analysis work is a success or not?\n",
    "minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HESsiXW5llX-"
   },
   "outputs": [],
   "source": [
    "how_success = '''Add your answer text here\n",
    "you can create python string using (') or (\") or 3('), like the text here. The 3(') string can be used \n",
    "to write paragraphs, comments in the beginning of functions, etc.. Your answer to the above question \n",
    "should replace this text.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdUoiMIOlmXq"
   },
   "outputs": [],
   "source": [
    "assert len(how_success) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(how_success) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQE6dqo6l1TZ"
   },
   "source": [
    "## What kind of challenges do you expect in your analysis?\n",
    "List at least 3 challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrAhBQhQl8Lh"
   },
   "outputs": [],
   "source": [
    "challenge_text = '''Add your answer text here\n",
    "you can create python string using (') or (\") or 3('), like the text here. The 3(') string can be used \n",
    "to write paragraphs, comments in the beginning of functions, etc.. Your answer to the above question \n",
    "should replace this text.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EedHa-Pll8X7"
   },
   "outputs": [],
   "source": [
    "assert len(challenge_text) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(how_success) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcJ8M6uWDeSE"
   },
   "source": [
    "<h2>Using the processed twitter data from yesterday's challenge</h2>.\n",
    "\n",
    "\n",
    "- Form a new data frame (named `cleanTweet`), containing columns $\\textbf{clean-text}$ and $\\textbf{polarity}$.\n",
    "\n",
    "- Write a function `text_category` that takes a value `p` and returns, depending on the value of p, a string `'positive'`, `'negative'` or `'neutral'`.\n",
    "\n",
    "- Apply this function (`text_category`) on the $\\textbf{polarity}$ column of `cleanTweet` in 1 above to form a new column called $\\textbf{score}$ in `cleanTweet`.\n",
    "\n",
    "- Visualize The $\\textbf{score}$ column using piechart and barchart\n",
    "\n",
    "<h5>Now we want to build a classification model on the clean tweet following the steps below:</h5>\n",
    "\n",
    "* Remove rows from `cleanTweet` where $\\textbf{polarity}$ $= 0$ (i.e where $\\textbf{score}$ = Neutral) and reset the frame index.\n",
    "* Construct a column $\\textbf{scoremap}$ Use the mapping {'positive':1, 'negative':0} on the $\\textbf{score}$ column\n",
    "* Create feature and target variables `(X,y)` from $\\textbf{clean-text}$ and $\\textbf{scoremap}$ columns respectively.\n",
    "* Use `train_test_split` function to construct `(X_train, y_train)` and `(X_test, y_test)` from `(X,y)`\n",
    "\n",
    "* Build an `SGDClassifier` model from the vectorize train text data. Use `CountVectorizer()` with a $\\textit{trigram}$ parameter.\n",
    "\n",
    "* Evaluate your model on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,json, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85WxmGNGDcBY"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/katenjoki/Twitter-Data-Analysis/fix_bug/data/covid19.json'\n",
    "df = pd.read_json(url,lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique languages check?\n",
    "df['lang'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exploratory Data Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=pd.DataFrame(columns=['original_text'])\n",
    "tweets['original_text']=df['text']\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values\n",
    "tweets.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cleaning the tweets </h2>\n",
    "\n",
    "* make all words lower_case\n",
    "* remove punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking random original tweet to see if the tweets are standardised\n",
    "print('Original text\\n',tweets.at[55,'original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text']=tweets['original_text'].str.lower()\n",
    "\n",
    "tweets['clean_text'] = tweets['clean_text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking random original tweet to see if the tweet was cleaned\n",
    "print('Clean text\\n',tweets.at[33,'clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to drop punctuation marks\n",
    "import string\n",
    "def clean_text_column(tweet):\n",
    "    for punctuation in string.punctuation:\n",
    "        tweet = tweet.replace(punctuation,\" \")\n",
    "    return tweet\n",
    "\n",
    "tweets['clean_text']=tweets['clean_text'].apply(clean_text_column)\n",
    "\n",
    "print('Clean tweet: \\n',tweets.at[33,'clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Original Text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=tweets.drop('original_text',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Visualization using WordCloud</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, ImageColorGenerator,STOPWORDS\n",
    "#STOPWORDS are words that don't contain enough significance\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(WordCloud(width=800,height=300,stopwords=STOPWORDS).generate(' '.join(tweets.clean_text .values)))\n",
    "plt.axis('off')\n",
    "plt.title('Most Frequent Words In Our Tweets',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>More Data Exploration...Top 10 words to appear in Tweets</h2>\n",
    "\n",
    "* Split sentences into words\n",
    "* Import package Counter to count frequency of words\n",
    "* Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = [tweet for tweet in tweets['clean_text']]\n",
    "words = [sent.split() for sent in sentences]\n",
    "\n",
    "print('The first two sentences\\n',sentences[:2],'\\n')#shows the first 2 sentences\n",
    "print('The words split from the first two sentences\\n',words[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "results = Counter()\n",
    "tweets['clean_text'].str.lower().str.split().apply(results.update)\n",
    "results =  pd.DataFrame.from_dict(results,orient='index',columns=['count'])\n",
    "results=results.sort_values(by='count',ascending=False)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising Top 10 words in tweets\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "results[:10].plot.barh(colormap='Spectral')\n",
    "plt.title('Top 10 words in tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sentiment Analysis</h2>\n",
    "\n",
    "* Import TextBlob to determine polarity of the clean text\n",
    "* Create new column score\n",
    "* Visualise score column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "cleanTweet = pd.DataFrame(columns=['clean_text','polarity'])\n",
    "cleanTweet['clean_text'] = tweets['clean_text']\n",
    "\n",
    "tweet_blob = [TextBlob(tweet) for tweet in cleanTweet['clean_text']]\n",
    "cleanTweet['polarity'] = [b.sentiment.polarity for b in tweet_blob]\n",
    "cleanTweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity=[]\n",
    "def text_category(pol):\n",
    "    for p in pol:\n",
    "        if p > 0:\n",
    "            score = 'positive'\n",
    "        elif p == 0:\n",
    "            score = 'neutral'\n",
    "        else:\n",
    "            score = 'negative'\n",
    "        polarity.append(score)\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTweet['score']=text_category(cleanTweet['polarity'])\n",
    "cleanTweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Piechart visualisation\n",
    "plt.pie(cleanTweet['score'].value_counts(),labels=cleanTweet['score'].unique(),autopct='%1.2f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barchart Visualisation\n",
    "sns.barplot(x=cleanTweet['score'].unique(),y=cleanTweet['score'].value_counts(),data=cleanTweet,palette='Accent')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building the Classification Model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTweet = cleanTweet[cleanTweet['score']!='neutral']\n",
    "cleanTweet.reset_index()\n",
    "cleanTweet.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTweet['scoremap']=\"\"\n",
    "cleanTweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleanTweet['scoremap'] = cleanTweet['score'].apply(lambda x:1 if x=='positive' else 0)\n",
    "cleanTweet.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "tweet_train, tweet_test = train_test_split(cleanTweet, test_size=0.3)\n",
    "tweet_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trigram(3,3)\n",
    "trigram_vectorizer = CountVectorizer(ngram_range=(3,3))\n",
    "trigram_vectorizer.fit(tweet_train['clean_text'].values)\n",
    "\n",
    "X_train_trigram = trigram_vectorizer.transform(tweet_train['clean_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_tf_idf_transformer = TfidfTransformer()\n",
    "trigram_tf_idf_transformer.fit(X_train_trigram)\n",
    "\n",
    "X_train_trigram_tf_idf = trigram_tf_idf_transformer.transform(X_train_trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train SDGClassifier </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tweet_train['scoremap'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def SDG_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.75, stratify=y)\n",
    "\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    valid_score = clf.score(X_valid, y_valid)\n",
    "    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDG_scores(X_train_trigram, y_train, 'Trigram Counts')\n",
    "SDG_scores(X_train_trigram_tf_idf, y_train, 'Trigram Tf-Idf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validation score of 0.95 is pretty good\n",
    "* Next we test the model using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = trigram_vectorizer.transform(tweet_test['clean_text'].values)\n",
    "X_test = trigram_tf_idf_transformer.transform(X_test)\n",
    "y_test = tweet_test['scoremap'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = SDG_scores(X_test, y_test,'Test Scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The test accuracy is 94% "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Challenge_ Day2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
